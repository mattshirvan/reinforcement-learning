{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random-sample one-step tabular Q-planning\n",
    "### Loop forever:\n",
    "   1. Select a state, S $\\in$ S, and an action, A $\\in$ A(S), at random\n",
    "   2. Send S, A to a sample model, and obtain a sample next reward, R, and a sample next state, S0\n",
    "   3. Apply one-step tabular Q-learning to S, A, R, S':\n",
    "####     Q(S, A) $\\gets$ Q(S, A) + $\\alpha$[R + $\\gamma$$max_{a}$ Q(S', a)  Q(S, A)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import random\n",
    "\n",
    "# Create terminal printer instance\n",
    "pp = pprint.PrettyPrinter(width=160, compact=True)\n",
    "\n",
    "# Q - plan with respect to Q\n",
    "Q = {(i//6+1, i%6+1): [0]*2 for i in range(36)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chō-han Bakuchi\n",
    "- Two standard six-sided dice are shaken in a bamboo cup by the dealer. \n",
    "- The cup is then overturned onto the floor.\n",
    "- Players then place their wagers on whether the sum total of numbers showing on the two dice will be \"Chō\" (even) or \"Han\" (odd).\n",
    "- The dealer then removes the cup, displaying the dice.\n",
    "- The winners collect their money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cho_han_sample(state, action):\n",
    "    \"\"\"\n",
    "    Return S',R from sample model of cho han\n",
    "    \"\"\"\n",
    "    \n",
    "    # bet was incorrect and player loses\n",
    "    reward = -1\n",
    "    \n",
    "    # Check if sum of dice is even and if decision matches state then reward == 1\n",
    "    if sum(state) % 2 == 0 and action % 2 == 0: reward = 1\n",
    "        \n",
    "    # Check if sum of dice is even and if decision matches state then reward == 1\n",
    "    elif sum(state) % 2 != 0 and action % 2 != 0: reward = 1\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_q_planning(alpha, gamma, runs, Q):\n",
    "    \"\"\"\n",
    "    Return random one-step sample Q-planning\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop forever:\n",
    "    for i in range(runs):\n",
    "        \n",
    "        # Select a state and an action at random\n",
    "        state = random.choice(list(Q.keys())); action = random.choice((0, 1))\n",
    "        \n",
    "        # Send S, A to a sample model, and obtain a sample next reward, R, and a sample next state, S'\n",
    "        s_prime = random.choice(list(Q.keys())); reward = cho_han_sample(state, action)\n",
    "\n",
    "        # Q(S, A) <-- Q(S, A) + a[R + gamma*max_aQ(S', a) - Q(S, A)]\n",
    "        Q[state][action] = Q[state][action] + (alpha**i)*(reward + gamma*max(Q[s_prime]) - Q[state][action]) \n",
    "    \n",
    "    # Return Q\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 1): [6.4903710731685736e-77, -7.205759403792816e-40],\n",
      " (1, 2): [-1.8788340662191044e-254, 8.933531975680016e-24],\n",
      " (1, 3): [4.398046511233722e-30, -5.120002726290166e-07],\n",
      " (1, 4): [-1.4411518807585633e-40, 2.5600000000000013e-06],\n",
      " (1, 5): [4.503599627370509e-37, -1.9342813113834156e-59],\n",
      " (1, 6): [-1.5845595994515667e-68, 2.854495385411944e-106],\n",
      " (2, 1): [-1.0, 2.3384026197294658e-115],\n",
      " (2, 2): [8.388627327352842e-17, -6.5536167772160054e-12],\n",
      " (2, 3): [-2.684354560000004e-20, 8.834257939534468e-168],\n",
      " (2, 4): [6.871947673600013e-26, -3.546382044571043e-32],\n",
      " (2, 5): [-7.922816251426476e-68, 1.8268770466636445e-110],\n",
      " (2, 6): [3.277009715199996e-11, -1.8446744073709616e-45],\n",
      " (3, 1): [5.629512504580121e-35, -2.0481310719973167e-08],\n",
      " (3, 2): [-1.5474250491067328e-61, 7.036874417766418e-33],\n",
      " (3, 3): [1.180591620725153e-49, -1.7592145512019396e-31],\n",
      " (3, 4): [-1.342177280000002e-19, 1.169575454322478e-114],\n",
      " (3, 5): [0.008000000000000002, -1.7422457186352182e-96],\n",
      " (3, 6): [-1.0240000000000006e-07, 6.71088640000001e-19],\n",
      " (4, 1): [-1.511074100421907e-54, 6.400000000000002e-05],\n",
      " (4, 2): [5.368709120000009e-21, -3.3554432000000048e-18],\n",
      " (4, 3): [-0.04000000000000001, 1.2259964326927237e-128],\n",
      " (4, 4): [7.365968401805587e-112, -1.717986918400003e-24],\n",
      " (4, 5): [-2.361183241434832e-50, 1.0737418240000018e-21],\n",
      " (4, 6): [4.1943044294967346e-16, -2.2517946255384837e-36],\n",
      " (5, 1): [2.991655416538638e-71, -1.0633823966279399e-86],\n",
      " (5, 2): [-8.796093022208022e-31, 5.789604461865892e-179],\n",
      " (5, 3): [1.6384000000000013e-10, -5.2428800000000056e-14],\n",
      " (5, 4): [-3.0948500982134647e-62, 6.610559688097601e-286],\n",
      " (5, 5): [1.8889465934264023e-52, -1.374389534720003e-26],\n",
      " (5, 6): [-8.192000000000005e-10, 0.2],\n",
      " (6, 1): [-2.305710192656371e-43, 2.7487790694400056e-27],\n",
      " (6, 2): [2.882310697492898e-41, -0.0016000000000000003],\n",
      " (6, 3): [-0.0003200000000000001, 1.267665203563151e-70],\n",
      " (6, 4): [1.2800000000000005e-05, -4.096000000000002e-09],\n",
      " (6, 5): [-1.0995116277760024e-28, 1.980704062856619e-66],\n",
      " (6, 6): [3.9231885846167166e-132, -2.4178516392292693e-57]}\n"
     ]
    }
   ],
   "source": [
    "# Show Q\n",
    "pp.pprint(one_step_q_planning(0.2, 0.9, 10000, Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
