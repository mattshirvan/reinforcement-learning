{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridworld Speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episodes \n",
    "episodes = 170\n",
    "\n",
    "# Start\n",
    "start = (4, 0)\n",
    "\n",
    "# Goal\n",
    "goal = (4, 6)\n",
    "\n",
    "# alpha \n",
    "alpha = 0.1\n",
    "\n",
    "# n-step\n",
    "n = 16\n",
    "\n",
    "# gamma \n",
    "gamma = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create():\n",
    "    \"\"\"\n",
    "    Create and return Q and arbitrary policy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create length and width to iterate grid\n",
    "    length = 10; width = 8\n",
    "\n",
    "    # Set of equiprobable actions\n",
    "    actions = [(-1, 0), (1, 0), (0, 1), (0, -1)]\n",
    "    # Policy\n",
    "    policy = {}; Q = {}\n",
    "\n",
    "    # Create states for policy\n",
    "    for i in range(length*width):\n",
    "\n",
    "        # Create row index\n",
    "        row = i // length\n",
    "\n",
    "        # Create column index\n",
    "        column = i % length\n",
    "\n",
    "        # Create policy\n",
    "        policy[(row, column)] = actions\n",
    "        \n",
    "        # Create Q(s,a)\n",
    "        Q[(row, column)] = [0 for action in actions]\n",
    "        \n",
    "    # Q and policy \n",
    "    return Q, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi(Q, policy, state):\n",
    "    \"\"\"\n",
    "    Target policy probability greedy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Epsilon\n",
    "    e = 0.1\n",
    "    \n",
    "    # Create action probability\n",
    "    Pr = {action: e/len(policy[state]) for action in policy[state]}\n",
    "    \n",
    "    # Exploitation Arg max a\n",
    "    argmax = Q[state].index(max(Q[state]))\n",
    "    \n",
    "    # greedy action\n",
    "    action = policy[state][argmax]\n",
    "    \n",
    "    # Set max probability\n",
    "    Pr[action] += (1-e)/len(policy[state])\n",
    "    \n",
    "    return Pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b(Q, policy,  state):\n",
    "    \"\"\"\n",
    "    Behavior policy probability e-greedy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set epsilon\n",
    "    e = 0.1\n",
    "    \n",
    "    # Create action probability\n",
    "    Pr = {action: e/len(policy[state]) for action in policy[state]}\n",
    "    \n",
    "    # Exploitation Arg max a\n",
    "    argmax = Q[state].index(max(Q[state]))\n",
    "    \n",
    "    # e-greedy action\n",
    "    action = policy[state][argmax]\n",
    "    \n",
    "    # Set max probability\n",
    "    Pr[action] = (1 - e)/len(policy[state])\n",
    "    \n",
    "    return Pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_v(V, policy, state):\n",
    "    \"\"\"\n",
    "    Target policy probability greedy w.r.t. V\n",
    "    \"\"\"\n",
    "    \n",
    "    # Epsilon\n",
    "    e = 0.1\n",
    "    \n",
    "    # Create action probability\n",
    "    Pr = {action: e/len(policy[state]) for action in policy[state]}\n",
    "    \n",
    "    # list of values\n",
    "    max_v = []\n",
    "    \n",
    "    # Exploitation max V(s')\n",
    "    for action in policy[state]:\n",
    "        \n",
    "        # create neighbor values\n",
    "        if (state[0] + action[0], state[1] + action[1]) in V:\n",
    "            max_v += [V[(state[0] + action[0], state[1] + action[1])]] \n",
    "        \n",
    "        # keep current state values for out of bounds\n",
    "        else:\n",
    "            \n",
    "            max_v += [V[state]]\n",
    "        \n",
    "    # Arg max a\n",
    "    argmax = max_v.index(max(max_v))\n",
    "    \n",
    "    # e-greedy action\n",
    "    action = policy[state][argmax]\n",
    "    \n",
    "    # Set max probability\n",
    "    Pr[action] += (1-e)/len(policy[state])\n",
    "    \n",
    "    return Pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_v(V, policy,  state):\n",
    "    \"\"\"\n",
    "    Behavior policy probability e-greedy w.r.t. V\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set epsilon\n",
    "    e = 0.1\n",
    "    \n",
    "    # Create action probability\n",
    "    Pr = {action: e/len(policy[state]) for action in policy[state]}\n",
    "    \n",
    "    # list of values\n",
    "    max_v = []\n",
    "    \n",
    "    # Exploitation max V(s')\n",
    "    for action in policy[state]:\n",
    "        \n",
    "        # create neighbor values\n",
    "        if (state[0] + action[0], state[1] + action[1]) in V:\n",
    "            max_v += [V[(state[0] + action[0], state[1] + action[1])]] \n",
    "        \n",
    "        # keep current state values for out of bounds\n",
    "        else:\n",
    "            \n",
    "            max_v += [V[state]]\n",
    "        \n",
    "    # Arg max a\n",
    "    argmax = max_v.index(max(max_v))\n",
    "    \n",
    "    # e-greedy action\n",
    "    action = policy[state][argmax]\n",
    "    \n",
    "    # Set max probability\n",
    "    Pr[action] = (1 - e)/len(policy[state])\n",
    "    \n",
    "    return Pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary(state):\n",
    "    \"\"\"\n",
    "    Returns if agent is in bounds\n",
    "    \"\"\"\n",
    "    # row boundary\n",
    "    row_boundary = (state[0] < 0 or state[0] > 7) \n",
    "        \n",
    "    # column boundary\n",
    "    column_boundary = (state[1] < 0 or state[1] > 9) \n",
    "    \n",
    "    # if not in bounds\n",
    "    return row_boundary or column_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_greedy(Q, policy, state, goal):\n",
    "    \"\"\"\n",
    "    Return an action based on e-greedy policy\n",
    "    \"\"\"\n",
    "\n",
    "    # Exploitation Arg max a\n",
    "    argmax = Q[state].index(max(Q[state]))\n",
    "    \n",
    "    # e-greedy action\n",
    "    action = policy[state][argmax]\n",
    "    \n",
    "    # Exploration\n",
    "    if random.random() < 0.1:\n",
    "        \n",
    "        # Explorative action\n",
    "        action = random.choice(policy[state])\n",
    "    \n",
    "    # e-greedy action\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(Q, policy, state):\n",
    "    \"\"\"\n",
    "    Return an action based on greedy policy\n",
    "    \"\"\"\n",
    "\n",
    "    # Exploitation Arg max a\n",
    "    argmax = Q[state].index(max(Q[state]))\n",
    "\n",
    "    # greedy action\n",
    "    return policy[state][argmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_greedy_v(V, policy, state, goal):\n",
    "    \"\"\"\n",
    "    Return an action based on e-greedy policy\n",
    "    \"\"\"\n",
    "\n",
    "    # list of values\n",
    "    max_v = []\n",
    "    \n",
    "    # Exploitation max V(s')\n",
    "    for action in policy[state]:\n",
    "        \n",
    "        # create neighbor values\n",
    "        if (state[0] + action[0], state[1] + action[1]) in V:\n",
    "            max_v += [V[(state[0] + action[0], state[1] + action[1])]] \n",
    "        \n",
    "        # keep current state values for out of bounds\n",
    "        else:\n",
    "            \n",
    "            max_v += [V[state]]\n",
    "        \n",
    "    # Arg max a\n",
    "    argmax = max_v.index(max(max_v))\n",
    "    \n",
    "    # e-greedy action\n",
    "    action = policy[state][argmax]\n",
    "    \n",
    "    # Exploration\n",
    "    if random.random() < 0.1:\n",
    "        \n",
    "        # Explorative action\n",
    "        action = random.choice(policy[state])\n",
    "    \n",
    "    # e-greedy action\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(state, action, goal):\n",
    "    \"\"\"\n",
    "    Return environment obervation\n",
    "    \"\"\"\n",
    "    \n",
    "    # S' after a\n",
    "    s_prime = (state[0] + action[0], state[1] + action[1])\n",
    "    \n",
    "    # r'\n",
    "    reward = 0\n",
    "    \n",
    "    # Check goal reached\n",
    "    if s_prime == goal:\n",
    "        \n",
    "        # S', R = 1 on termination\n",
    "        return s_prime, 1\n",
    "    \n",
    "    # check if out of bounds\n",
    "    if boundary(s_prime):\n",
    "        \n",
    "        # Remain in state\n",
    "        s_prime = state\n",
    "        \n",
    "        # consequence\n",
    "        reward = -1\n",
    "    \n",
    "    # S', R'\n",
    "    return s_prime, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_sarsa(alpha, n, episodes, start, goal):\n",
    "    \"\"\"\n",
    "    n-step SARSA for estimating Q = q* or q_pi\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize Q(s, a) arbitrarily, for all s of S, a of A\n",
    "    # Initialize ⇡ to be \"-greedy with respect to Q, or to a fixed given policy\n",
    "    Q, policy = create()\n",
    "    \n",
    "    # All store and access operations (for St and Rt) can take their index mod n + 1\n",
    "    store = []\n",
    "    \n",
    "    # Loop for each episode:\n",
    "    for i in range(episodes):\n",
    "        \n",
    "        # Initialize S0 != terminal\n",
    "        S = start\n",
    "        \n",
    "        # Select and store an action A0 = pi(·|S0)\n",
    "        A = e_greedy(Q, policy, S, goal)\n",
    "        \n",
    "        # Store S0 != terminal\n",
    "        store.append((S, A, 0))\n",
    "        \n",
    "        # T <-- inf\n",
    "        T = float('inf');  t = tau = 0\n",
    "        \n",
    "        # Loop for t = 0, 1, 2,... : Until t' = T - 1\n",
    "        while tau != T-1:\n",
    "\n",
    "            # If t < T, then:\n",
    "            if t < T:\n",
    "                \n",
    "                # Take action At\n",
    "                S, R = move(S, A, goal)\n",
    "                \n",
    "                # Observe and store the next reward as Rt+1 and the next state as St+1\n",
    "                store.append((S, A, R))\n",
    "                \n",
    "                # If St+1 is terminal, then T <-- t + 1\n",
    "                if S == goal: T = t + 1\n",
    "                    \n",
    "                # Select and store an action A0 = pi(·|S0)\n",
    "                else: A = e_greedy(Q, policy, S, goal)\n",
    "                \n",
    "            # t' <-- t - n +1 (t' is the time whose state’s estimate is being updated)\n",
    "            tau = t - n + 1\n",
    "            \n",
    "            # If t' >= 0:\n",
    "            if tau >= 0:\n",
    "            \n",
    "                # G <-- sum(i=t'+1 to min(t'+n,T)) gamma^i-t'-1*Ri\n",
    "                G = sum([store[i][2] for i in range(tau + 1, min(tau + n, T)+1)])\n",
    "                \n",
    "                # If t'+n < T, then: G <-- G + gamma^n*Q(St', At')\n",
    "                if tau+n < T: G = G + Q[store[tau+n][0]][policy[store[tau][0]].index(store[tau][1])]\n",
    "\n",
    "                # Q(St', At') <-- Q(St', At') + a[G - Q(St', At')]\n",
    "                Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])] = Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])] + alpha*(G - Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])])\n",
    "            \n",
    "            # Until t' = T - 1\n",
    "            t += 1\n",
    "            \n",
    "    # Return q*\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_off_policy_sarsa(alpha, n, episodes, start, goal):\n",
    "    \"\"\"\n",
    "    Off-policy n-step Sarsa for estimating Q = q* or q_p⇡\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input: an arbitrary behavior policy b such that b(a|s) > 0, for all s of S, a of A\n",
    "    # Initialize Q(s, a) arbitrarily, for all s of S, a of A\n",
    "    # Initialize pi to be greedy with respect to Q, or as a fixed given policy\n",
    "    Q, policy = create()\n",
    "    \n",
    "    # All store and access operations (for St, At, and Rt) can take their index mod n + 1\n",
    "    store = []\n",
    "\n",
    "    # Loop for each episode:\n",
    "    for _ in range(episodes):\n",
    "        \n",
    "        # Initialize S0 != terminal\n",
    "        S = start\n",
    "        \n",
    "        # Select an Action A0\n",
    "        A = e_greedy(Q, policy, S, goal)\n",
    "        \n",
    "        # store S0 != terminal and A0 ⇠ b(·|S0)\n",
    "        store.append((S, A, 0))\n",
    "        \n",
    "        # T <-- infinity\n",
    "        T = float('inf');  t = tau = 0\n",
    "        \n",
    "        # Loop for t = 0, 1, 2,... : Until tau = T - 1\n",
    "        while tau != T-1:\n",
    "            \n",
    "            # If t < T, then:\n",
    "            if t < T:\n",
    "                \n",
    "                # Take action At Observe the next reward as Rt+1 and the next state as St+1\n",
    "                S, R = move(S, A, goal)\n",
    "                \n",
    "                # store the next reward as Rt+1 and the next state as St+1\n",
    "                store.append((S, A, R))\n",
    "                \n",
    "                # If St+1 is terminal, then: T <-- t + 1\n",
    "                if S == goal: T = t + 1\n",
    "                    \n",
    "                # else: Select and store an action At+1 ⇠ b(·|St+1)\n",
    "                else: A = e_greedy(Q, policy, S, goal)\n",
    "\n",
    "            # tau <-- t - n +1\n",
    "            tau = t - n + 1\n",
    "            \n",
    "            # If tau >=  0:\n",
    "            if tau >= 0:\n",
    "                \n",
    "                # p <-- 1\n",
    "                rho = 1\n",
    "                \n",
    "                # from i=tau+1 to min(tau+n,T-1)\n",
    "                for i in range(tau + 1, min(tau + n, T-1)+1):\n",
    "                    \n",
    "                    # p <-- Projection of pi(Ai|Si) / b(Ai|Si)\n",
    "                    rho *= (pi(Q, policy, store[i][0])[store[i][1]]/b(Q, policy, store[i][0])[store[i][1]])\n",
    "\n",
    "                # G <-- Sum from i=tau+1 to min(tau+n,T) of gamma^i-tau-1 * Ri\n",
    "                G = sum([store[i][2] for i in range(tau + 1, min(tau + n, T)+1)])\n",
    "                \n",
    "                # If tau + n < T, then: G <-- G + gamma^n*Q(Stau+n, Atau+n) \n",
    "                if tau + n < T: G = G + Q[store[tau+n][0]][policy[store[tau][0]].index(store[tau][1])]\n",
    "\n",
    "                # Q(Stau, Atau) <-- Q(Stau , Atau) + a*p*[G - Q(Stau, Atau)]\n",
    "                Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])] = Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])] + alpha*rho*(G - Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])]) \n",
    "            \n",
    "            # Until t' = T - 1\n",
    "            t += 1\n",
    "            \n",
    "    # Q = q*\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_per_decision(alpha, n, episodes, start, goal):\n",
    "    \"\"\"\n",
    "    Off-policy n-step Sarsa per-decision importance sampling\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input: policy\n",
    "    V, policy = create()\n",
    "    \n",
    "    # Initialize V(s) arbitrarily, for all s of S\n",
    "    V = V.fromkeys(V, 0)\n",
    "    \n",
    "    # All store and access operations (for St, At, and Rt) can take their index mod n + 1\n",
    "    store = []\n",
    "\n",
    "    # Loop for each episode:\n",
    "    for _ in range(episodes):\n",
    "        \n",
    "        # Initialize S0 != terminal\n",
    "        S = start\n",
    "        \n",
    "        # Select an Action A0\n",
    "        A = e_greedy_v(V, policy, S, goal)\n",
    "        \n",
    "        # store S0 != terminal and A0 ⇠ b(·|S0)\n",
    "        store.append((S, A, 0))\n",
    "        \n",
    "        # T <-- infinity\n",
    "        T = float('inf');  t = tau = 0\n",
    "        \n",
    "        # Loop for t = 0, 1, 2,... : Until tau = T - 1\n",
    "        while tau != T-1:\n",
    "            \n",
    "            # If t < T, then:\n",
    "            if t < T:\n",
    "                \n",
    "                # Take action At Observe the next reward as Rt+1 and the next state as St+1\n",
    "                S, R = move(S, A, goal)\n",
    "                \n",
    "                # store the next reward as Rt+1 and the next state as St+1\n",
    "                store.append((S, A, R))\n",
    "                \n",
    "                # If St+1 is terminal, then: T <-- t + 1\n",
    "                if S == goal: T = t + 1\n",
    "                    \n",
    "                # else: Select and store an action At+1 ⇠ b(·|St+1)\n",
    "                else: A = e_greedy_v(V, policy, S, goal)\n",
    "\n",
    "            # tau <-- t - n +1\n",
    "            tau = t - n + 1\n",
    "            \n",
    "            # If tau >=  0:\n",
    "            if tau >= 0:\n",
    "                \n",
    "                # p <-- 1\n",
    "                rho = 1\n",
    "                \n",
    "                # from i=tau+1 to min(tau+n,T-1)\n",
    "                for i in range(tau + 1, min(tau + n, T-1)+1):\n",
    "                    \n",
    "                    # p <-- Projection of pi(Ai|Si) / b(Ai|Si)\n",
    "                    rho *= (pi_v(V, policy, store[i][0])[store[i][1]]/b_v(V, policy, store[i][0])[store[i][1]])\n",
    "\n",
    "                # G <-- Sum from i=tau+1 to min(tau+n,T) of gamma^i-tau-1 * Ri\n",
    "                G = sum([store[i][2] for i in range(tau + 1, min(tau + n, T)+1)])\n",
    "                \n",
    "                # If tau + n < T, then: G <-- G + gamma^n*Q(Stau+n, Atau+n) \n",
    "                if tau + n < T: G = rho*G + (1-rho)*V[store[tau+n][0]]\n",
    "\n",
    "                # V(Stau) <-- V(Stau) + a*p*[G - V(Stau)]\n",
    "                V[store[tau][0]] = V[store[tau][0]] + alpha*(G - V[store[tau][0]]) \n",
    "            \n",
    "            # Until t' = T - 1\n",
    "            t += 1\n",
    "            \n",
    "    # V = v*\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_tree(alpha, n, episodes, start, goal):\n",
    "    \"\"\"\n",
    "    n-step tree backup algorithm estimating Q = q* or q_p⇡\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input: an arbitrary behavior policy b such that b(a|s) > 0, for all s of S, a of A\n",
    "    # Initialize Q(s, a) arbitrarily, for all s of S, a of A\n",
    "    # Initialize pi to be greedy with respect to Q, or as a fixed given policy\n",
    "    Q, policy = create()\n",
    "    \n",
    "    # All store and access operations (for St, At, and Rt) can take their index mod n + 1\n",
    "    store = []\n",
    "\n",
    "    # Loop for each episode:\n",
    "    for _ in range(episodes):\n",
    "        \n",
    "        # Initialize S0 != terminal\n",
    "        S = start\n",
    "        \n",
    "        # Select an Action A0\n",
    "        A = e_greedy(Q, policy, S, goal)\n",
    "        \n",
    "        # store S0 != terminal and A0 ⇠ b(·|S0)\n",
    "        store.append((S, A, 0))\n",
    "        \n",
    "        # T <-- infinity\n",
    "        T = float('inf');  t = tau = 0\n",
    "        \n",
    "        # Loop for t = 0, 1, 2,... : Until tau = T - 1\n",
    "        while tau != T-1:\n",
    "            \n",
    "            # If t < T, then:\n",
    "            if t < T:\n",
    "                \n",
    "                # Take action At Observe the next reward as Rt+1 and the next state as St+1\n",
    "                S, R = move(S, A, goal)\n",
    "                \n",
    "                # store the next reward as Rt+1 and the next state as St+1\n",
    "                store.append((S, A, R))\n",
    "                \n",
    "                # If St+1 is terminal, then: T <-- t + 1\n",
    "                if S == goal: T = t + 1\n",
    "                    \n",
    "                # else: Select and store an action At+1 ⇠ b(·|St+1)\n",
    "                else: A = e_greedy(Q, policy, S, goal)\n",
    "\n",
    "            # tau <-- t - n +1\n",
    "            tau = t - n + 1\n",
    "            \n",
    "            # If tau >=  0:\n",
    "            if tau >= 0:\n",
    "                \n",
    "                # If t + 1 >= T: \n",
    "                if t+1 >= T: \n",
    "                    \n",
    "                    # G <-- RT\n",
    "                    G = store[T][2]\n",
    "               \n",
    "                # else: \n",
    "                else:\n",
    "                    \n",
    "                    # G <-- Rt+1 + gamma *SUM a pi(a|St+1)*Q(St+1,a)\n",
    "                    G = store[t+1][2] + pi(Q, policy, store[t+1][0])[store[t+1][1]] * Q[store[t+1][0]][policy[store[t+1][0]].index(store[t+1][1])]\n",
    "                    \n",
    "                # Loop for k = min(t, T  1) down through tau + 1:\n",
    "                for k in range(min(t+1, T), tau+1, 1):\n",
    "                    \n",
    "                    # if a == Ak\n",
    "                    sum_a = 0\n",
    "                    \n",
    "                    # Sum if a != Ak \n",
    "                    if A != store[k][1]:\n",
    "                    \n",
    "                        sum_a += pi(Q, policy, store[k][0])[store[k][1]]*Q(store[k][0], store[k][1]) + pi(Q, policy, store[k][0])[store[k][1]]*Q(store[k][0], store[k][1]) \n",
    "                    \n",
    "                    # G <-- Rk + Gammma*SUM a!=Ak pi(a|Sk)*Q(Sk, a) + gamma*pi(Ak|Sk)*G\n",
    "                    G = store[k][2] + sum_a + pi(Q, policy, store[k][0])[store[k][1]]*G\n",
    "                    \n",
    "                # If tau + n < T, then: G <-- G + gamma^n*Q(Stau+n, Atau+n) \n",
    "                if tau + n < T: G = G + Q[store[tau+n][0]][policy[store[tau+n][0]].index(store[tau+n][1])]\n",
    "\n",
    "                # Q(Stau, Atau) <-- Q(Stau , Atau) + a*p*[G - Q(Stau, Atau)]\n",
    "                Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])] = Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])] + alpha*(G - Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])]) \n",
    "            \n",
    "            # Until t' = T - 1\n",
    "            t += 1\n",
    "            \n",
    "    # Q = q*\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_qsigma(alpha, gamma, n, episodes, start, goal):\n",
    "    \"\"\"\n",
    "    Off-policy n-step Q(sigma) for estimating Q = q* or qp⇡\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input: an arbitrary behavior policy b such that b(a|s) > 0, for all s of S, a of A\n",
    "    # Initialize Q(s, a) arbitrarily, for all s of S, a of A\n",
    "    # Initialize pi to be greedy with respect to Q, or as a fixed given policy\n",
    "    Q, policy = create()\n",
    "    \n",
    "    # All store and access operations (for St, At, and Rt) can take their index mod n + 1\n",
    "    store = []; rho = []; sigma = []; sampling = False; G = V = 0\n",
    "\n",
    "    # Loop for each episode:\n",
    "    for _ in range(episodes):\n",
    "        \n",
    "        # Initialize S0 != terminal\n",
    "        S = start\n",
    "        \n",
    "        # Select an Action A0\n",
    "        A = e_greedy(Q, policy, S, goal)\n",
    "        \n",
    "        # store S0 != terminal and A0 ⇠ b(·|S0)\n",
    "        store.append((S, A, 0))\n",
    "        \n",
    "        # T <-- infinity\n",
    "        T = float('inf');  t = tau = 0\n",
    "        \n",
    "        # Loop for t = 0, 1, 2,... : Until tau = T - 1\n",
    "        while tau != T-1:\n",
    "            \n",
    "            # If t < T, then:\n",
    "            if t < T:\n",
    "                \n",
    "                # Take action At Observe the next reward as Rt+1 and the next state as St+1\n",
    "                S, R = move(S, A, goal)\n",
    "                \n",
    "                # store the next reward as Rt+1 and the next state as St+1\n",
    "                store.append((S, A, R))\n",
    "                \n",
    "                # If St+1 is terminal, then: T <-- t + 1\n",
    "                if S == goal: T = t + 1\n",
    "                    \n",
    "                # else: Select and store an action At+1 ⇠ b(·|St+1)\n",
    "                else: \n",
    "                    \n",
    "                    # Select an action At+1 ⇠ b(·|St+1)\n",
    "                    A = e_greedy(Q, policy, S, goal)\n",
    "                    \n",
    "                    # store an action At+1 ⇠ b(·|St+1)\n",
    "                    store.append((S, A, 0))\n",
    "                    \n",
    "                    # select and store sigma \n",
    "                    if sampling == False: sigma.append(1)\n",
    "                    \n",
    "                    else: sigma.append(0)\n",
    "                        \n",
    "                    if sigma[-1] == 1: sampling = True\n",
    "                    \n",
    "                    else: sampling = False\n",
    "                    \n",
    "                    # store pi(At+1|St+1)/b(At+1|St+1)\n",
    "                    rho.append(pi(Q, policy, S)[A]/b(Q, policy, S)[A])\n",
    "                    \n",
    "            # tau <-- t - n +1\n",
    "            tau = t - n + 1\n",
    "            \n",
    "            # If tau >=  0:\n",
    "            if tau >= 0:\n",
    "                \n",
    "                # If t + 1 >= T: \n",
    "                if t+1 >= T: \n",
    "                    \n",
    "                    # G <-- Q(St+1, At+1)\n",
    "                    G = Q[store[t+1][0]][policy[store[t+1][0]].index(store[t+1][1])]\n",
    "                    \n",
    "                # Loop for k = min(t, T  1) down through tau + 1:\n",
    "                for k in range(min(t+1, T), tau+1, 1):\n",
    "\n",
    "                    # k at T\n",
    "                    if k == T:\n",
    "                        \n",
    "                        # G <-- RT \n",
    "                        G = store[T][2]\n",
    "                        \n",
    "                    else:\n",
    "                        # V <--  SUM a pi(a|Sk)*Q(Sk,a)\n",
    "                        V += pi(Q, policy, store[k][0])[policy[store[k][0]].index(store[k][1])] * Q[store[k][0]][policy[store[k][0]].index(store[k][1])]\n",
    "                        \n",
    "                        # G <-- Rk + gamma *SUM a pi(a|St+1)*Q(St+1,a)\n",
    "                        G = store[k][2] + (sigma[k]*rho[k] + gamma*(1 - sigma[k])*pi(Q, policy, store[k][0])[store[k][1]]) * (G - Q[store[k][0]][policy[store[k][0]].index(store[k][1])]) + gamma*V\n",
    "\n",
    "                # Q(Stau, Atau) <-- Q(Stau , Atau) + a*p*[G - Q(Stau, Atau)]\n",
    "                Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])] = Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])] + alpha*(G - Q[store[tau][0]][policy[store[tau][0]].index(store[tau][1])]) \n",
    "                \n",
    "            # Until t' = T - 1\n",
    "            t += 1\n",
    "            \n",
    "    # Q = q*\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_sarsa\n",
      "{(0, 0): [-58.095084186175264, 0, 0, -0.5779235664798654],\n",
      " (0, 1): [-66.83049827114556, 0, 0, -1.0986301265423835],\n",
      " (0, 2): [-64.83211873129659, 0, -0.5424521572479947, -0.9715730294672039],\n",
      " (0, 3): [-53.98692989088134, 0, -156.797718905483, -0.14273805764160638],\n",
      " (0, 4): [-63.57234081850753, 0, -14.265528265344017, -1.3055771011442097],\n",
      " (0, 5): [-65.41339697426444, 0, -0.13614290586634542, -1.210508849874543],\n",
      " (0, 6): [-45.543673200408904, 0, -56.18222855915444, -0.504035916439755],\n",
      " (0, 7): [-30.61717883282239, 0, -45.93827446922617, -1.1752419104979768],\n",
      " (0, 8): [-34.59734422726361, 0, -52.30079399023459, -0.12902893580512387],\n",
      " (0, 9): [-12.300303378720542, 0, -36.71265181206305, 0],\n",
      " (1, 0): [-64.39259705985083, -4.765144617382513, 0, -4.990375168327162],\n",
      " (1, 1): [-77.08336837880687, -3.939173120590491, -2.490075488345636, -0.9980976767944867],\n",
      " (1, 2): [-68.29910112779658, -10.40244862180167, -1.3150715900604346, -2.545214862631349],\n",
      " (1, 3): [-63.15469201278661, -3.397224260218019, -3.757106336151087, -1.3387603352501638],\n",
      " (1, 4): [-55.96847840802181, -4.916916999913231, -5.63274624664295, -1.402078144293955],\n",
      " (1, 5): [-49.55356560909616, -1.491824542153176, -24.15208156923319, -0.6385989836288747],\n",
      " (1, 6): [-45.64498000265352, -2.3830858461494855, -43.631675076228866, -1.0507998969384056],\n",
      " (1, 7): [-33.378779744032634, -2.530031163384834, -49.435999685318095, -0.30373570303819597],\n",
      " (1, 8): [-36.777375079114634, -0.7647553532667895, -37.23453111810134, -0.5397279703019487],\n",
      " (1, 9): [-28.913303604678532, -0.6493476217573562, 0.0, 0],\n",
      " (2, 0): [-63.19804389828519, -6.0054829456727, 0, -3.4210559503497353],\n",
      " (2, 1): [-71.4897410621571, -4.99719975567349, -0.9136633952262277, -1.2154954228181032],\n",
      " (2, 2): [-57.146839450095364, -4.926830450060578, -1.0062580363602558, -2.953728445654784],\n",
      " (2, 3): [-48.3507720649425, -6.076023880322308, -0.7774563970279165, -3.1711268214401445],\n",
      " (2, 4): [-52.59946602291283, -6.560359789054694, -4.781322851568393, -0.9569601528879961],\n",
      " (2, 5): [-43.27554434307181, -1.5894973530861294, -4.439913402457735, 0],\n",
      " (2, 6): [-2.9585205220974746, 0.0, -22.800349590759804, 0],\n",
      " (2, 7): [-18.626231168961638, -0.25525273939276183, -0.4132136594647109, 0],\n",
      " (2, 8): [0, -2.5688987640376624, 0.0, 0],\n",
      " (2, 9): [0, 0.0, 0, 0],\n",
      " (3, 0): [-61.95956870220323, -5.008393632610582, 0, -2.852347735838065],\n",
      " (3, 1): [-71.60699057971645, -6.067517954876903, -1.880124153530869, -3.2247473482343274],\n",
      " (3, 2): [-56.672572608751075, -6.823756188636843, -0.8585908078440742, -3.538192728977947],\n",
      " (3, 3): [-53.77567701148872, -6.0859263838029865, -2.801006793712167, -4.049290662604485],\n",
      " (3, 4): [-49.206553101371924, -6.188053997803924, -11.759842715534187, -0.26089105605827223],\n",
      " (3, 5): [-48.112427259496194, -1.790421566376637, -3.281220217246641, 0],\n",
      " (3, 6): [0, 0, 0, -0.026331183392137837],\n",
      " (3, 7): [-21.96250010123621, 0, 0, 0],\n",
      " (3, 8): [0, 0, 0, 0],\n",
      " (3, 9): [0, 0, 0, 0],\n",
      " (4, 0): [-64.17650921762046, -6.018198682459908, -2.151109943540666, -2.5616285724402164],\n",
      " (4, 1): [-67.97432740961011, -6.973177393138885, -8.061198791025305, -4.0012386458066915],\n",
      " (4, 2): [-56.93173584857636, -4.83138180244511, -1.5914930102096114, -2.322284619965012],\n",
      " (4, 3): [-46.073290853049684, -6.1490199978521165, -2.0877225296592914, -2.2587491161006445],\n",
      " (4, 4): [-43.15558670955278, -5.2697878335184, -0.5030934734173349, -0.8740511040839143],\n",
      " (4, 5): [-46.25111911794242, -5.691503893767263, -1.1227696848026065, 0],\n",
      " (4, 6): [-48.22352166552326, 0, -0.21935409677938245, 0],\n",
      " (4, 7): [-19.17788126300429, 0, 0, 0],\n",
      " (4, 8): [0, 0, 0, 0],\n",
      " (4, 9): [0, 0, 0, 0],\n",
      " (5, 0): [-50.494701687031515, -5.464240683061352, 0, -2.227331070849881],\n",
      " (5, 1): [-51.383444020319544, -8.723637704594156, -1.491843744709152, -1.8832036688554104],\n",
      " (5, 2): [-22.42572892815273, -6.551203569040288, -118.47263294838864, -1.9440890631313015],\n",
      " (5, 3): [-48.675185068069304, -3.81053286219682, -2.970437325367158, -1.5820935402012302],\n",
      " (5, 4): [-45.23035894688388, -5.798626150315452, -22.260597780307428, -0.29484250917187305],\n",
      " (5, 5): [-37.34232182555508, -6.1534078384376665, 0.04104863961278274, -0.0400244561125331],\n",
      " (5, 6): [0, 0, -0.849635941401087, 0],\n",
      " (5, 7): [0, 0, -3.3297069087651803, 0],\n",
      " (5, 8): [0, 0, 0, 0],\n",
      " (5, 9): [0, 0, 0, 0],\n",
      " (6, 0): [-29.324041069181664, -6.349501177164701, 0, -2.0979895429170443],\n",
      " (6, 1): [-36.79114786188525, -7.095944765197293, -0.3613995761628454, -0.3373334205731166],\n",
      " (6, 2): [-8.271819628028489, -5.61075429066605, -0.9621699540101458, 0],\n",
      " (6, 3): [0, -5.734147493795381, -0.5274350807551138, -2.4835847161921274],\n",
      " (6, 4): [-40.52484257976933, -5.660582611125188, 0.3597031, -1.0466321865706572],\n",
      " (6, 5): [0, -2.2855097261379327, -11.844608269949012, 0],\n",
      " (6, 6): [0, 0, 0, 0],\n",
      " (6, 7): [0, 0, 0, 0],\n",
      " (6, 8): [0, 0, 0, 0],\n",
      " (6, 9): [0, 0, 0, 0],\n",
      " (7, 0): [0, -7.346203030533903, 0, -0.26294576433119377],\n",
      " (7, 1): [0, -7.16421444924902, -0.08084401883354182, -0.11074840979907202],\n",
      " (7, 2): [0, -1.3135504109084222, -0.8108287234864634, 0],\n",
      " (7, 3): [0, 0, 0, 0],\n",
      " (7, 4): [0, -6.0130428767531106, 0, 0],\n",
      " (7, 5): [0, 0, 0, 0],\n",
      " (7, 6): [0, 0, 0, 0],\n",
      " (7, 7): [0, 0, 0, 0],\n",
      " (7, 8): [0, 0, 0, 0],\n",
      " (7, 9): [0, 0, 0, 0]}\n",
      "\n",
      "n_step_off_policy_sarsa\n",
      "{(0, 0): [-59.682316614152036, 0, 0, -0.16352590592151464],\n",
      " (0, 1): [-67.04581747672837, 0, 0, -1.1835775691947839],\n",
      " (0, 2): [-53.15021502457326, 0, -0.5338306335086915, -7.863543243753308],\n",
      " (0, 3): [-63.543391860742766, 0, -0.11188065622392451, -1.1819659959322406],\n",
      " (0, 4): [-53.630761882775374, 0, -14.266502084018839, 0],\n",
      " (0, 5): [-54.916873382823916, 0, -7.3615951381119, -0.9657621690151381],\n",
      " (0, 6): [-45.053464791657476, 0, -9.079314017950264, 0.0],\n",
      " (0, 7): [-46.154753360122896, 0, -0.04612146371963323, -0.6459588673140579],\n",
      " (0, 8): [-22.441901158932744, 0, -199.91407999025031, -0.217052504435706],\n",
      " (0, 9): [-36.479471521175654, 0, -248.53052657613827, 0],\n",
      " (1, 0): [-239.52163697426866, -7.054107564210545, 0, -1.670939427864306],\n",
      " (1, 1): [-62.19924147699191, -5.881575075593829, -4.249458299286046, -0.39090768580458163],\n",
      " (1, 2): [-63.62293149076286, -7.220265924425563, -0.11567740303849008, -1.0604624192304444],\n",
      " (1, 3): [-48.41875207283575, -4.843225534708466, -18.167894465282973, -0.7113907976149529],\n",
      " (1, 4): [-63.87114054897804, -5.535994863446019, -0.40424940023521205, -0.8151231262154379],\n",
      " (1, 5): [-54.64961043684776, -3.466740615074679, -20.601008129741185, -2.8728934082600145e-20],\n",
      " (1, 6): [-56.82553805580897, -5.2190212442665525, -3.377405280579516, -0.6605483110911086],\n",
      " (1, 7): [-18.878555786919016, -0.7768711090067555, -132.23882407016808, -9.806841548957563e-07],\n",
      " (1, 8): [-57.80017862376508, -2.373026084326102, -4.166792287530429, -0.19],\n",
      " (1, 9): [0.0, -0.6410283775690416, -155.23322154265756, 0],\n",
      " (2, 0): [-68.75912258503057, -4.343679877045624, 0, -1.377034013344122],\n",
      " (2, 1): [-70.26970994592294, -10.002590266396851, -0.11824138007957716, -1.4034584601000057],\n",
      " (2, 2): [-60.39667518702701, -4.711372334067028, -4.343368046399435, -1.1298220233994916],\n",
      " (2, 3): [-65.73660306733055, -8.060079831872647, -0.11708059854027729, -1.4810723264729566],\n",
      " (2, 4): [-47.55579389650942, -1.5887755578615153, -3.7983109137548747, -0.4176530714617246],\n",
      " (2, 5): [-37.009471136195344, -4.794773967970017, -0.11616351432287733, -0.6841752653559751],\n",
      " (2, 6): [-19.125813535274983, -3.8625776224571347, -9.136674404187012, 0.0],\n",
      " (2, 7): [0, -3.1376909371653063, -0.6769332187091393, 0],\n",
      " (2, 8): [0, 0.0, -7.216988907599141, 0],\n",
      " (2, 9): [0, 0.0, 0, 0],\n",
      " (3, 0): [-70.29813619697225, -7.757983897112034, 0, -1.9090037669650017],\n",
      " (3, 1): [-61.078779448246095, -4.369927334002642, -2.459034917227691, -1.605361206335266],\n",
      " (3, 2): [-65.31499193976346, -7.217116373363191, -0.526633703281967, -1.3610060180596977],\n",
      " (3, 3): [-47.60392315262705, -4.811005234912919, -9.335884414056324, -0.5153977224200846],\n",
      " (3, 4): [-34.25437649896544, -6.658313453840214, -0.18115562847036304, -0.6795742535886942],\n",
      " (3, 5): [-12.032761951406474, -3.839441387495319, -5.851876593080648, 0.0],\n",
      " (3, 6): [0, -4.353461322092879, -0.2028510768474272, 0],\n",
      " (3, 7): [0, 0, 0, 0],\n",
      " (3, 8): [0, 0, 0, 0],\n",
      " (3, 9): [0, 0, 0, 0],\n",
      " (4, 0): [-65.46638018502146, -6.002795080296146, -0.5420096086688043, -1.3484758888966077],\n",
      " (4, 1): [-61.52613082092514, -8.298240833033876, -4.057483743449117, -1.7401885411850022],\n",
      " (4, 2): [-50.32822829290551, -6.878730801114094, -3.43924735091777, -0.9311624794203176],\n",
      " (4, 3): [-28.064973140096296, -6.8472783683275615, -0.061239570989938534, 0.4176653689283676],\n",
      " (4, 4): [-12.822087622818502, -3.718414417348809, -0.01920476563930018, -0.16233880926143096],\n",
      " (4, 5): [-11.195843121222886, -6.146165284089329, -0.11744109479524023, 0],\n",
      " (4, 6): [-0.9012985427830255, 0, 0, 0],\n",
      " (4, 7): [0, 0, 0, 0],\n",
      " (4, 8): [0, 0, 0, 0],\n",
      " (4, 9): [0, 0, 0, 0],\n",
      " (5, 0): [-6.452771509564829, -7.926978185025047, 0, -0.5124389491299468],\n",
      " (5, 1): [-12.3442492653916, -6.083271841589404, 0, -0.20007840052781153],\n",
      " (5, 2): [-5.913419739199428, -7.542086875684493, -0.1107719235965214, -0.6907073852426153],\n",
      " (5, 3): [-3.6482340811730767, -4.3864093376473665, -2.006165883838433, -0.2107876971434556],\n",
      " (5, 4): [-9.884694416794929, -4.1729110758309345, -0.07818759484805789, 0],\n",
      " (5, 5): [-3.011224120213851, -0.8885828721767903, 0.2501323652165626, 0],\n",
      " (5, 6): [0, 0, -0.41673187474734275, 0],\n",
      " (5, 7): [0, 0, 0, 0],\n",
      " (5, 8): [0, 0, 0, 0],\n",
      " (5, 9): [0, 0, 0, 0],\n",
      " (6, 0): [0, -0.9893936707750981, 0, 0],\n",
      " (6, 1): [0, -3.649606303602262, 0, -0.044844415042141206],\n",
      " (6, 2): [-1.3895567780611096, -2.702918905941261, 0, -0.1774501458442988],\n",
      " (6, 3): [-0.370353485391945, -5.122841313418608, -0.0931294556696026, 0],\n",
      " (6, 4): [0, -0.7464597244198491, -3.1393634478164616, 0],\n",
      " (6, 5): [0, 0, -0.021604955319815614, 0],\n",
      " (6, 6): [0, 0, 0, 0],\n",
      " (6, 7): [0, 0, 0, 0],\n",
      " (6, 8): [0, 0, 0, 0],\n",
      " (6, 9): [0, 0, 0, 0],\n",
      " (7, 0): [0, 0, 0, 0],\n",
      " (7, 1): [0, 0, 0, 0],\n",
      " (7, 2): [0, -0.9535725043076841, 0, 0],\n",
      " (7, 3): [0, -0.573497919278454, 0, 0],\n",
      " (7, 4): [0, 0, 0, 0],\n",
      " (7, 5): [0, 0, 0, 0],\n",
      " (7, 6): [0, 0, 0, 0],\n",
      " (7, 7): [0, 0, 0, 0],\n",
      " (7, 8): [0, 0, 0, 0],\n",
      " (7, 9): [0, 0, 0, 0]}\n",
      "\n",
      "n_step_per_decision\n",
      "{(0, 0): -13.27942019626338,\n",
      " (0, 1): -6.556648702787141,\n",
      " (0, 2): -5.555893055224935,\n",
      " (0, 3): -15.041425063366306,\n",
      " (0, 4): -6.367396172257942,\n",
      " (0, 5): -12.279949642649942,\n",
      " (0, 6): -5.396389843409074,\n",
      " (0, 7): -6.011595209265613,\n",
      " (0, 8): -13.928031256537945,\n",
      " (0, 9): -12.000153885205727,\n",
      " (1, 0): -8.939361914959564,\n",
      " (1, 1): 2.397698423448154,\n",
      " (1, 2): -5.867397708382128,\n",
      " (1, 3): -14.979860036668605,\n",
      " (1, 4): -1.1875801142185514e-05,\n",
      " (1, 5): -3.1239598049725754,\n",
      " (1, 6): 0.15833190676689926,\n",
      " (1, 7): -3.8840852058027746,\n",
      " (1, 8): -11.200265373802766,\n",
      " (1, 9): -9.75527209655714,\n",
      " (2, 0): -13.053583620362524,\n",
      " (2, 1): 1.097074392065896,\n",
      " (2, 2): -8.570456402772054,\n",
      " (2, 3): -6.392837593765723,\n",
      " (2, 4): -4.630959458937273e-06,\n",
      " (2, 5): 0.7246258341850863,\n",
      " (2, 6): 0.1013675300413597,\n",
      " (2, 7): -5.309054889164077,\n",
      " (2, 8): -8.613326208922418,\n",
      " (2, 9): 0,\n",
      " (3, 0): -12.023669293559065,\n",
      " (3, 1): -5.24549871372856e-05,\n",
      " (3, 2): -5.909174580028025,\n",
      " (3, 3): -2.2599683057949013e-07,\n",
      " (3, 4): -0.35546120075521936,\n",
      " (3, 5): 0.6390675213265826,\n",
      " (3, 6): 0.14267993604743853,\n",
      " (3, 7): 2.0960823989263027,\n",
      " (3, 8): 0,\n",
      " (3, 9): 0,\n",
      " (4, 0): -10.44661882748147,\n",
      " (4, 1): 3.0494582906138283e-07,\n",
      " (4, 2): 2.1316924648712005e-06,\n",
      " (4, 3): 2.322256386400372e-11,\n",
      " (4, 4): -0.0008315257861885765,\n",
      " (4, 5): 0.12852727839766753,\n",
      " (4, 6): 0.4508380746970388,\n",
      " (4, 7): 2.2646840379576045,\n",
      " (4, 8): 0,\n",
      " (4, 9): 0,\n",
      " (5, 0): -9.053577901679676e-05,\n",
      " (5, 1): 1.690068885732222e-07,\n",
      " (5, 2): 4.4995014374352994e-06,\n",
      " (5, 3): 5.020018306081442e-06,\n",
      " (5, 4): 0.005392743907941097,\n",
      " (5, 5): 0.0073717368203647686,\n",
      " (5, 6): 2.0174040729503258,\n",
      " (5, 7): 0,\n",
      " (5, 8): 0,\n",
      " (5, 9): 0,\n",
      " (6, 0): 0.387383427108252,\n",
      " (6, 1): -0.00059516705182547,\n",
      " (6, 2): -0.04937744149272203,\n",
      " (6, 3): 0.0,\n",
      " (6, 4): 0.005788994799412523,\n",
      " (6, 5): -0.004835990596986181,\n",
      " (6, 6): 2.0025209497295755,\n",
      " (6, 7): 0,\n",
      " (6, 8): 0,\n",
      " (6, 9): 0,\n",
      " (7, 0): -0.4267548701954796,\n",
      " (7, 1): -6.113108013766802,\n",
      " (7, 2): -0.12133114443450492,\n",
      " (7, 3): -0.018504360290458415,\n",
      " (7, 4): 0,\n",
      " (7, 5): 0,\n",
      " (7, 6): 0.3918385323861698,\n",
      " (7, 7): 0,\n",
      " (7, 8): 0,\n",
      " (7, 9): 0}\n",
      "\n",
      "n_step_tree\n",
      "{(0, 0): [-6.48917431239857e+42, 0, 0, -6.92203723845604e+42],\n",
      " (0, 1): [-1.5605422606971843e+44, 0, 0, 0],\n",
      " (0, 2): [-2.443265646652707e+43, 0, -4.859374022685161e+43, -1.1227522222531855e+41],\n",
      " (0, 3): [-3.456299395629137e+44, 0, 0, -3.170128011705651e+44],\n",
      " (0, 4): [-4.158382147898758e+44, 0, -1.8018943722944083e+44, -2.2039857654772307e+44],\n",
      " (0, 5): [-4.389903522548009e+44, 0, -3.1506223144736048e+44, -4.039166625530033e+44],\n",
      " (0, 6): [-2.674505076848263e+44, 0, -2.4641874224206784e+44, -2.531253598380136e+44],\n",
      " (0, 7): [-2.5298894844772486e+44, 0, -3.3675050621345752e+44, -1.6353795998607807e+44],\n",
      " (0, 8): [-2.9005769943133865e+44, 0, -2.2001437819171707e+44, 0],\n",
      " (0, 9): [-4.303281127071334e+43, 0, -2.920550542239593e+43, 0],\n",
      " (1, 0): [-8.576166134079557e+41, -1.2407927462012415e+43, 0, 0],\n",
      " (1, 1): [-2.375166168309042e+43, -8.397931913823599e+43, 0, 0],\n",
      " (1, 2): [-9.213800240630077e+43, -5.362225152109013e+43, -4.8570247791191044e+41, -2.6090981876077393e+44],\n",
      " (1, 3): [-2.835157409202444e+44, -3.4167151213566906e+44, -2.4877371340539584e+44, -3.4867943704958307e+44],\n",
      " (1, 4): [-3.334361022999668e+44, -4.358144893581928e+44, -3.825660055392964e+44, -3.985452241578751e+44],\n",
      " (1, 5): [-4.537781190720959e+44, -4.636220814929193e+44, -3.2680847402902464e+44, -4.065172462702953e+44],\n",
      " (1, 6): [-4.231007129708817e+44, -2.9362283296528637e+44, -4.324466860228716e+44, -4.036723850342345e+44],\n",
      " (1, 7): [-2.770211017952727e+44, -3.3539344127806758e+44, -4.096330613939223e+44, -2.589002208000549e+44],\n",
      " (1, 8): [-1.991754669905232e+44, -2.849692531912614e+44, -2.3915652414093132e+44, -1.2177314758054635e+44],\n",
      " (1, 9): [-7.527606942399144e+43, -2.5953981529944637e+43, -7.451897552193543e+43, 0],\n",
      " (2, 0): [-8.576166134079557e+41, -6.076480438906161e+42, 0, -3.00673082038837e+40],\n",
      " (2, 1): [-6.362696972162773e+42, 0, -1.162392029413356e+43, -1.6645311596154161e+43],\n",
      " (2, 2): [-7.163242819117387e+43, -9.083362162204442e+43, -3.51619472399019e+42, 0],\n",
      " (2, 3): [0, -3.008695239917789e+44, -2.8827273129562564e+43, 0],\n",
      " (2, 4): [-1.3326569492399997e+44, -3.411747355746051e+44, 0, -1.2068809935810696e+44],\n",
      " (2, 5): [-1.1160696715928127e+44, -4.498545392085499e+44, -3.609897191573752e+44, -3.9214608971017864e+44],\n",
      " (2, 6): [-2.0267135741521875e+44, -4.296812983819326e+44, -1.4212892811816732e+44, -1.6052578103952138e+44],\n",
      " (2, 7): [-1.6918387492622033e+44, -2.67106101706676e+44, -1.5694020262550112e+44, -2.6673208066613253e+44],\n",
      " (2, 8): [-5.311269251001841e+43, -3.3124938007291925e+43, -2.7569742331791483e+44, -7.60136635120136e+42],\n",
      " (2, 9): [0, -3.637142509276022e+43, -4.770496023046817e+43, 0],\n",
      " (3, 0): [-8.576166134079557e+41, -2.2272956842587835e+42, 0, -8.705271095595235e+41],\n",
      " (3, 1): [-3.549165786862744e+42, -3.407706374039816e+41, -2.5657059399867907e+40, -164215534732623.12],\n",
      " (3, 2): [-2.9197149840625875e+43, -4.867905855172869e+43, -848.9856029767736, 0],\n",
      " (3, 3): [0, 0, 0, 0],\n",
      " (3, 4): [0, -1.3893474740721922e+44, 0, -3.3654581011347842e+41],\n",
      " (3, 5): [0, -1.0635310979220305e+44, 0, 0],\n",
      " (3, 6): [0, -1.860606326500893e+44, 0, -2801.1978924323766],\n",
      " (3, 7): [-3132.4820483901804, -1.72701053981092e+44, -9.565224536914629e+41, 0],\n",
      " (3, 8): [0, -5.380679084470847e+43, 0, 0],\n",
      " (3, 9): [0, 0, 0, 0],\n",
      " (4, 0): [-9.086670106041618e+42, -1.2666606624053032e+42, -2.949666055015801e+43, -2.4167531692796647e+41],\n",
      " (4, 1): [-4.662796102990243e+43, -3.4364109797413614e+41, -2.964492148386377e+43, -420.44122331941884],\n",
      " (4, 2): [-3.0971672084455984e+43, -1147.4030741491806, -3.1002519236062923e+41, 0],\n",
      " (4, 3): [0, 0, 0, 0],\n",
      " (4, 4): [0, 0, 0, 0],\n",
      " (4, 5): [0, 0, 0, 0],\n",
      " (4, 6): [0, -1.8387017128356984e+43, 0, 0],\n",
      " (4, 7): [0, -3282.23026719253, 0, 0],\n",
      " (4, 8): [0, 0, 0, 0],\n",
      " (4, 9): [0, 0, 0, 0],\n",
      " (5, 0): [0, -1.6487607048714696e+43, 0, -2.117779237959338e+41],\n",
      " (5, 1): [-2.954560146548732e+43, -6.723022290692161e+43, -3.505751737671516e+42, 0],\n",
      " (5, 2): [-522.8797402809348, -6.034172117461342e+36, -2.904436202603143e+43, 0],\n",
      " (5, 3): [0, 0, 0, 0],\n",
      " (5, 4): [0, 0, 0, 0],\n",
      " (5, 5): [0, 0, 0, 0],\n",
      " (5, 6): [0, 0, 0, 0],\n",
      " (5, 7): [0, 0, 0, 0],\n",
      " (5, 8): [0, 0, 0, 0],\n",
      " (5, 9): [0, 0, 0, 0],\n",
      " (6, 0): [0, 0, 0, 0],\n",
      " (6, 1): [0, -2.963081837029465e+43, 0, 0],\n",
      " (6, 2): [0, -495.98649977634113, 0, 0],\n",
      " (6, 3): [0, 0, 0, 0],\n",
      " (6, 4): [0, 0, 0, 0],\n",
      " (6, 5): [0, 0, 0, 0],\n",
      " (6, 6): [0, 0, 0, 0],\n",
      " (6, 7): [0, 0, 0, 0],\n",
      " (6, 8): [0, 0, 0, 0],\n",
      " (6, 9): [0, 0, 0, 0],\n",
      " (7, 0): [0, 0, 0, 0],\n",
      " (7, 1): [0, 0, 0, 0],\n",
      " (7, 2): [0, 0, 0, 0],\n",
      " (7, 3): [0, 0, 0, 0],\n",
      " (7, 4): [0, 0, 0, 0],\n",
      " (7, 5): [0, 0, 0, 0],\n",
      " (7, 6): [0, 0, 0, 0],\n",
      " (7, 7): [0, 0, 0, 0],\n",
      " (7, 8): [0, 0, 0, 0],\n",
      " (7, 9): [0, 0, 0, 0]}\n",
      "\n",
      "n_step_qsigma\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-216-6314cc537b26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"n_step_qsigma\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_step_qsigma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-215-a1c6c31e5d9c>\u001b[0m in \u001b[0;36mn_step_qsigma\u001b[1;34m(alpha, gamma, n, episodes, start, goal)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[1;31m# store pi(At+1|St+1)/b(At+1|St+1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                     \u001b[0mrho\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# tau <-- t - n +1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-8710ad750c0a>\u001b[0m in \u001b[0;36mpi\u001b[1;34m(Q, policy, state)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Create action probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mPr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Exploitation Arg max a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# create terminal printer instance\n",
    "pp = pprint.PrettyPrinter(width=160, compact=True)\n",
    "\n",
    "# n-step boostrapping algorithms\n",
    "print(\"n_step_sarsa\")\n",
    "pp.pprint(n_step_sarsa(alpha, n, episodes, start, goal))\n",
    "print()\n",
    "print(\"n_step_off_policy_sarsa\")\n",
    "pp.pprint(n_step_off_policy_sarsa(alpha, n, episodes, start, goal))\n",
    "print()\n",
    "print(\"n_step_per_decision\")\n",
    "pp.pprint(n_step_per_decision(alpha, n, episodes, start, goal))\n",
    "print()\n",
    "print(\"n_step_tree\")\n",
    "pp.pprint(n_step_tree(alpha, n, episodes, start, goal))\n",
    "print()\n",
    "print(\"n_step_qsigma\")\n",
    "pp.pprint(n_step_qsigma(alpha, gamma, n, episodes, start, goal))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
